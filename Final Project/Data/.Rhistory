lines(1-rf_spec, rf_sens, col = "blue", lty = 2, lwd = 2)
legend("topleft", legend = c("GLM ROC", "RF ROC"), lty = c(1,2), col = c("red", "blue"), lwd = 2)
vif(logitmodel)
anova(logitmodel)
varImpPlot(rf_model, sort = T)
par(mfrow=c(1,2))
partialPlot(rf_model, train, 'bmi', which.class = '1',
main = "PDP of BMI for Stroke = 1")
partialPlot(rf_model, train, 'bmi', which.class = '0',
main = "PDP of BMI for Stroke = 0")
par(mfrow=c(1,2))
partialPlot(rf_model, train, 'age', which.class = '1',
main = "PDP of Age for Stroke = 1")
partialPlot(rf_model, train, 'age', which.class = '0',
main = "PDP of Age for Stroke = 0")
par(mfrow=c(1,2))
partialPlot(rf_model, train, 'avg_glucose_level', which.class = '1',
main = "PDP for Stroke = 1")
partialPlot(rf_model, train, 'avg_glucose_level', which.class = '0',
main = "PDP for Stroke = 0")
bmi_1 <- density(train$bmi[which(train$stroke=='1')])
bmi_0 <- density(train$bmi[which(train$stroke=='0')])
#par(mfrow=c(1,2))
plot(bmi_1, xlim=range(bmi_1$x,bmi_0$x), ylim=range(bmi_1$y,bmi_0$y), col = "red",
main = "Density Plot for BMI on Stroke Status",
xlab = "BMI", lwd=2)
lines(bmi_0, col = "grey", lwd= 2, lty = 2)
legend("topright", legend=c("stroke = 1", "stroke = 0"), lty = c(1,2),
col = c("red", "grey"), lwd=2)
gluc_1 <- density(train$avg_glucose_level[which(train$stroke=='1')])
gluc_0 <- density(train$avg_glucose_level[which(train$stroke=='0')])
#par(mfrow=c(1,2))
plot(gluc_1, xlim=range(gluc_1$x,gluc_0$x), ylim=range(0,0.06), col = "red",
main = "Density Plot for Avg Glucose Level on Stroke Status",
xlab = "Average Glucose Level", lwd=2)
lines(bmi_0, col = "grey", lwd= 2, lty = 2)
legend("topright", legend=c("stroke = 1", "stroke = 0"), lty = c(1,2),
col = c("red", "grey"), lwd=2)
age_1 <- density(train$age[which(train$stroke=='1')])
age_0 <- density(train$age[which(train$stroke=='0')])
#par(mfrow=c(1,2))
plot(age_1, xlim=range(age_1$x,age_0$x), ylim=range(0,0.06), col = "red",
main = "Density Plot for Age on Stroke Status",
xlab = "Age", lwd=2)
lines(bmi_0, col = "grey", lwd= 2, lty = 2)
legend("topright", legend=c("stroke = 1", "stroke = 0"), lty = c(1,2),
col = c("red", "grey"), lwd=2)
library(MatchIt)
match <- matchit(stroke ~ ., data = data,
method = NULL, distance = "glm")
summary(match)
match_nn <- matchit(stroke ~ ., data = data,
method = "nearest", distance = "glm")
match_nn
summary(match_nn, un = F)
plot(match_nn, type = "jitter", interactive = FALSE)
plot(match_nn, type = "density", interactive = FALSE,
which.xs = ~ gender+age+hypertension+heart_disease+ever_married+work_type+Residence_type+avg_glucose_level+bmi+smoking_status)
data_match_nn <- match.data(match_nn)
data_match_nn <- data_match_nn[, c("stroke", setdiff(names(data_match_nn), "stroke"))]
n=3
nn = nrow(data_match_nn)
nn_log_misclass_rate <- vector(mode = "numeric", length = n)
nn_rf_misclass_rate <- vector(mode = "numeric", length = n)
nn_log_auc <- vector(mode = "numeric", length = n)
nn_rf_auc <- vector(mode = "numeric", length = n)
for (i in 1:n){
set.seed(i)
index_nn <- sample(1:nn, size = nn*.7, replace = F)
nn_train_x <- data_match_nn[index_nn, 2:11]
nn_test_x <- data_match_nn[-index_nn, 2:11]
nn_train_y <- data_match_nn[index_nn, 1]
nn_test_y <- data_match_nn[-index_nn, 1]
nn_train <- data_match_nn[index_nn, 1:11]
nn_test <-data_match_nn[-index_nn, 1:11]
nn_log <- glm(stroke ~., family = binomial(link = logit), data = nn_train)
summary(nn_log)
nn_pred_logitmod <- predict(nn_log, newdata = nn_test, type = "response")
nn_log_predicted_class <- ifelse(nn_pred_logitmod > 0.5, 1, 0)
nn_log_predicted_class <- factor(nn_log_predicted_class, levels = c(0, 1))
nn_log_error <- table(actual = nn_test_y, predicted = nn_log_predicted_class)
nn_log_misclass_rate[i] <- 1-sum(diag(nn_log_error))/sum(nn_log_error)
nn_log_auc[i] <- auc(roc(nn_log_predicted_class, nn_test_y))
nn_rf_model <- randomForest(stroke~.,data = nn_train, xtest = nn_test_x,
ytest=nn_test_y, mtry=optimal.m, nodesize=optimal.depth
ntree=optimal.ntrees, keep.forest = TRUE)
data_match_nn <- match.data(match_nn)
data_match_nn <- data_match_nn[, c("stroke", setdiff(names(data_match_nn), "stroke"))]
n=3
nn = nrow(data_match_nn)
nn_log_misclass_rate <- vector(mode = "numeric", length = n)
nn_rf_misclass_rate <- vector(mode = "numeric", length = n)
nn_log_auc <- vector(mode = "numeric", length = n)
nn_rf_auc <- vector(mode = "numeric", length = n)
for (i in 1:n){
set.seed(i)
index_nn <- sample(1:nn, size = nn*.7, replace = F)
nn_train_x <- data_match_nn[index_nn, 2:11]
nn_test_x <- data_match_nn[-index_nn, 2:11]
nn_train_y <- data_match_nn[index_nn, 1]
nn_test_y <- data_match_nn[-index_nn, 1]
nn_train <- data_match_nn[index_nn, 1:11]
nn_test <-data_match_nn[-index_nn, 1:11]
nn_log <- glm(stroke ~., family = binomial(link = logit), data = nn_train)
summary(nn_log)
nn_pred_logitmod <- predict(nn_log, newdata = nn_test, type = "response")
nn_log_predicted_class <- ifelse(nn_pred_logitmod > 0.5, 1, 0)
nn_log_predicted_class <- factor(nn_log_predicted_class, levels = c(0, 1))
nn_log_error <- table(actual = nn_test_y, predicted = nn_log_predicted_class)
nn_log_misclass_rate[i] <- 1-sum(diag(nn_log_error))/sum(nn_log_error)
nn_log_auc[i] <- auc(roc(nn_log_predicted_class, nn_test_y))
nn_rf_model <- randomForest(stroke~.,data = nn_train, xtest = nn_test_x,
ytest=nn_test_y, mtry=optimal.m, nodesize=optimal.depth,
ntree=optimal.ntrees, keep.forest = TRUE)
nn_rf_predicted_class <- nn_rf_model$test$predicted
nn_rf_error <- table(actual = nn_test_y, predicted = nn_rf_predicted_class)
nn_rf_misclass_rate[i] <- 1-sum(diag(nn_rf_error))/sum(nn_rf_error)
nn_rf_auc[i] <- auc(roc(nn_rf_predicted_class,nn_test_y))
}
nn_results_misclass = data.frame(Log_Error = nn_log_misclass_rate, RF_Error = nn_rf_misclass_rate)
nn_results_auc = data.frame(Log_AUC = nn_log_auc, RF_AUC = nn_rf_auc)
nn_summary_results_misclass=describe(nn_results_misclass)
nn_summary_results_auc = describe(nn_results_auc)
nn_results_misclass
nn_results_auc
nn_summary_results_misclass
nn_summary_results_auc
data_match_nn <- match.data(match_nn)
data_match_nn <- data_match_nn[, c("stroke", setdiff(names(data_match_nn), "stroke"))]
n=3
nn = nrow(data_match_nn)
nn_log_misclass_rate <- vector(mode = "numeric", length = n)
nn_rf_misclass_rate <- vector(mode = "numeric", length = n)
nn_log_auc <- vector(mode = "numeric", length = n)
nn_rf_auc <- vector(mode = "numeric", length = n)
for (i in 1:n){
set.seed(i)
index_nn <- sample(1:nn, size = nn*.7, replace = F)
nn_train_x <- data_match_nn[index_nn, 2:11]
nn_test_x <- data_match_nn[-index_nn, 2:11]
nn_train_y <- data_match_nn[index_nn, 1]
nn_test_y <- data_match_nn[-index_nn, 1]
nn_train <- data_match_nn[index_nn, 1:11]
nn_test <-data_match_nn[-index_nn, 1:11]
nn_log <- glm(stroke ~., family = binomial(link = logit), data = nn_train)
summary(nn_log)
nn_pred_logitmod <- predict(nn_log, newdata = nn_test, type = "response")
nn_log_predicted_class <- ifelse(nn_pred_logitmod > 0.5, 1, 0)
nn_log_predicted_class <- factor(nn_log_predicted_class, levels = c(0, 1))
nn_log_error <- table(actual = nn_test_y, predicted = nn_log_predicted_class)
nn_log_misclass_rate[i] <- 1-sum(diag(nn_log_error))/sum(nn_log_error)
nn_log_auc[i] <- auc(roc(nn_log_predicted_class, nn_test_y))
nn_rf_model <- randomForest(stroke~.,data = nn_train, xtest = nn_test_x,
ytest=nn_test_y,
ntree=300, keep.forest = TRUE)
nn_rf_predicted_class <- nn_rf_model$test$predicted
nn_rf_error <- table(actual = nn_test_y, predicted = nn_rf_predicted_class)
nn_rf_misclass_rate[i] <- 1-sum(diag(nn_rf_error))/sum(nn_rf_error)
nn_rf_auc[i] <- auc(roc(nn_rf_predicted_class,nn_test_y))
}
nn_results_misclass = data.frame(Log_Error = nn_log_misclass_rate, RF_Error = nn_rf_misclass_rate)
nn_results_auc = data.frame(Log_AUC = nn_log_auc, RF_AUC = nn_rf_auc)
nn_summary_results_misclass=describe(nn_results_misclass)
nn_summary_results_auc = describe(nn_results_auc)
nn_results_misclass
nn_results_auc
nn_summary_results_misclass
nn_summary_results_auc
data_match_nn <- match.data(match_nn)
data_match_nn <- data_match_nn[, c("stroke", setdiff(names(data_match_nn), "stroke"))]
n=3
nn = nrow(data_match_nn)
nn_log_misclass_rate <- vector(mode = "numeric", length = n)
nn_rf_misclass_rate <- vector(mode = "numeric", length = n)
nn_log_auc <- vector(mode = "numeric", length = n)
nn_rf_auc <- vector(mode = "numeric", length = n)
for (i in 1:n){
set.seed(i)
index_nn <- sample(1:nn, size = nn*.7, replace = F)
nn_train_x <- data_match_nn[index_nn, 2:11]
nn_test_x <- data_match_nn[-index_nn, 2:11]
nn_train_y <- data_match_nn[index_nn, 1]
nn_test_y <- data_match_nn[-index_nn, 1]
nn_train <- data_match_nn[index_nn, 1:11]
nn_test <-data_match_nn[-index_nn, 1:11]
nn_log <- glm(stroke ~., family = binomial(link = logit), data = nn_train)
summary(nn_log)
nn_pred_logitmod <- predict(nn_log, newdata = nn_test, type = "response")
nn_log_predicted_class <- ifelse(nn_pred_logitmod > 0.5, 1, 0)
nn_log_predicted_class <- factor(nn_log_predicted_class, levels = c(0, 1))
nn_log_error <- table(actual = nn_test_y, predicted = nn_log_predicted_class)
nn_log_misclass_rate[i] <- 1-sum(diag(nn_log_error))/sum(nn_log_error)
nn_log_auc[i] <- auc(roc(nn_log_predicted_class, nn_test_y))
nn_rf_model <- randomForest(stroke~.,data = nn_train, xtest = nn_test_x,
ytest=nn_test_y, mtry=optimal.m, nodesize=optimal.depth,
ntree=optimal.ntrees, keep.forest = TRUE)
nn_rf_predicted_class <- nn_rf_model$test$predicted
nn_rf_error <- table(actual = nn_test_y, predicted = nn_rf_predicted_class)
nn_rf_misclass_rate[i] <- 1-sum(diag(nn_rf_error))/sum(nn_rf_error)
nn_rf_auc[i] <- auc(roc(nn_rf_predicted_class,nn_test_y))
}
nn_results_misclass = data.frame(Log_Error = nn_log_misclass_rate, RF_Error = nn_rf_misclass_rate)
nn_results_auc = data.frame(Log_AUC = nn_log_auc, RF_AUC = nn_rf_auc)
nn_summary_results_misclass=describe(nn_results_misclass)
nn_summary_results_auc = describe(nn_results_auc)
nn_results_misclass
nn_results_auc
nn_summary_results_misclass
nn_summary_results_auc
log_sorted_indices <- order(-pred_logitmod)
us_stroke = 795000/332915073
prevelance = round((nrow(test))*us_stroke)
log_top_prob <- pred_logitmod[log_sorted_indices[1:prevelance]]
print(paste("The highest probability of stroke patient using GLM is", paste(round(log_top_prob, digits = 3), collapse = " and ")))
rf_prob <- data.frame(rf_model$test$votes)
rf_prob <- rf_prob$X1
rf_sorted_indices <- order(-rf_prob)
rf_top_prob <- rf_prob[rf_sorted_indices[1:prevelance]]
print(paste("The highest probability of stroke patient using RF is", paste(round(rf_top_prob, digits = 3), collapse = " and ")))
rf_stroke_pred <- sum(rf_predicted_class == 1)
rf_prev_comparison = c(rf_stroke_pred,prevelance)
log_stroke_pred <- sum(log_predicted_class == 1)
log_prev_comparison = c(log_stroke_pred, prevelance)
print(paste("The number of predicted stroke using RF vs prevalence of stroke in test set is", paste(rf_prev_comparison, collapse = " vs ")))
print(paste("The number of predicted stroke using GLM vs prevalence of stroke in test set is", paste(log_prev_comparison, collapse = " vs ")))
rf_predicted_class
rf_predicted_class == 1
rf_predicted_class
log_sorted_indices <- order(-pred_logitmod)
us_stroke = 795000/332915073
prevelance = round((nrow(test))*us_stroke)
log_top_prob <- pred_logitmod[log_sorted_indices[1:prevelance]]
print(paste("The highest probability of stroke patient using GLM is", paste(round(log_top_prob, digits = 3), collapse = " and ")))
rf_prob <- data.frame(rf_model$test$votes)
rf_prob <- rf_prob$X1
rf_sorted_indices <- order(-rf_prob)
rf_top_prob <- rf_prob[rf_sorted_indices[1:prevelance]]
print(paste("The highest probability of stroke patient using RF is", paste(round(rf_top_prob, digits = 3), collapse = " and ")))
rf_stroke_pred <- sum(rf_predicted_class == 1)
rf_prev_comparison = c(rf_stroke_pred,prevelance)
log_stroke_pred <- sum(log_predicted_class == 1)
log_prev_comparison = c(log_stroke_pred, prevelance)
print(paste("The number of predicted stroke using RF vs prevalence of stroke in test set is", paste(rf_prev_comparison, collapse = " vs ")))
print(paste("The number of predicted stroke using GLM vs prevalence of stroke in test set is", paste(log_prev_comparison, collapse = " vs ")))
rf_stroke_pred <- sum(rf_top_prob > 5)
rf_stroke_pred <- length(rf_top_prob > 5)
rf_stroke_pred <- sum(rf_top_prob > 0.5)
rf_prev_comparison = c(rf_stroke_pred,prevelance)
log_stroke_pred <- sum(log_predicted_class > 0.5)
log_stroke_pred <- sum(log_top_prob > 0.5)
log_stroke_pred <- sum(log_top_prob > 0.5)
log_sorted_indices <- order(-pred_logitmod)
us_stroke = 795000/332915073
prevelance = round((nrow(test))*us_stroke)
log_top_prob <- pred_logitmod[log_sorted_indices[1:prevelance]]
print(paste("The highest probability of stroke patient using GLM is", paste(round(log_top_prob, digits = 3), collapse = " and ")))
rf_prob <- data.frame(rf_model$test$votes)
rf_prob <- rf_prob$X1
rf_sorted_indices <- order(-rf_prob)
rf_top_prob <- rf_prob[rf_sorted_indices[1:prevelance]]
print(paste("The highest probability of stroke patient using RF is", paste(round(rf_top_prob, digits = 3), collapse = " and ")))
rf_stroke_pred <- sum(rf_top_prob > 0.5)
rf_prev_comparison = c(rf_stroke_pred,prevelance)
log_stroke_pred <- sum(log_top_prob > 0.5)
log_prev_comparison = c(log_stroke_pred, prevelance)
print(paste("The number of predicted stroke using RF vs prevalence of stroke in test set is", paste(rf_prev_comparison, collapse = " vs ")))
print(paste("The number of predicted stroke using GLM vs prevalence of stroke in test set is", paste(log_prev_comparison, collapse = " vs ")))
reduced_log <- stepAIC(logitmodel, direction = "both")
r_log_pred <- predict(reduced_log, newdata = test, type = "response")
r_log_pred_class <- ifelse(r_log_pred > 0.5, 1,0)
length(r_log_pred_class[r_log_pred_class == "1"])
r_log_auc <- auc(roc(r_log_pred_class,test_y))
knitr::opts_chunk$set(message=FALSE, tidy.opts=list(width.cutoff=40), tidy=TRUE)
library(easypackages)
libraries("ggplot2","lubridate","tictoc","tidyverse","viridis","hrbrthemes","gridExtra","grid","formatR","broom")
source("./Functions/All_Functions.R") # adds the function
options(scipen = 1, digits = 2)
df1 <- read.csv(file = "../Data/Processed/TG_Questionnaire_1.csv",header = TRUE, sep = ",") # Reads from csv change the name to match your file
colnames(df1)[1] <- "Knowledge"
df2=df1%>%filter(Grade!="")
df3=df2%>%filter(International!="")
df4=df3%>%filter(Knowledge!="")
p4=ggplot(df2, aes(x="", y="", fill=Grade)) +
geom_bar(stat="identity", width=1) +
ggtitle("Anticipated Grades") +
coord_polar("y", start=0)+
scale_fill_viridis(discrete = T) +
theme_void() # remove background, grid, numeric labels
p4
p1=ggplot(df2, aes(x=Department, fill=Grade)) +
geom_bar(position="stack", stat="count")+
scale_fill_viridis(discrete = T) +
ggtitle("Anticipated Grades by Department") +
theme_classic() +
ylab("")+
ylim(0,6)+
xlab("")+
geom_text(position="stack",stat='count', aes(label=..count..), colour="red",vjust=-1,size=3)+
theme(axis.text.x = element_text(angle = 45, hjust = 1))
ggsave("../Results/Graphs/Department_vs_Grade_Bar.jpg",width=10,height=10,p1)
p1
p2=ggplot(df2, aes(x=Programming, fill=Grade)) +
geom_bar(position="stack", stat="count")+
scale_fill_viridis(discrete = T) +
ggtitle("Anticipated Grades by Prior Knowledge of Statistical Programs") +
theme_classic() +
ylab("")+
xlab("Do You Have Prior Statistical Programming Knowledge?")+
ylim(0,20)+
geom_text(position="stack",stat='count', aes(label=..count..), colour="red",vjust=-0.5,size=4)
ggsave("../Results/Graphs/Program_vs_Grade_Bar.jpg",width=10,height=10,p2)
p2
p5=ggplot(df4, aes(x=Knowledge, fill=Grade)) +
geom_bar(position="stack", stat="count")+
scale_fill_viridis(discrete = T) +
ggtitle("Anticipated Grades by Prior Knowledge of Statistics") +
theme_classic() +
ylab("")+
xlab("Do You Have Prior Statistical Knowledge?")+
ylim(0,25)+
geom_text(position="stack",stat='count', aes(label=..count..), colour="red",vjust=-0.5,size=4)
ggsave("../Results/Graphs/Knowledge_vs_Grade_Bar.jpg",width=10,height=10,p5)
p5
p3=ggplot(df3, aes(x=International, fill=Grade)) +
geom_bar(position="stack", stat="count")+
scale_fill_viridis(discrete = T) +
ggtitle("Anticipated Grades by Natonality") +
theme_classic() +
ylab("")+
xlab("International?")+
ylim(0,20)+
geom_text(position="stack",stat='count', aes(label=..count..), colour="red",vjust=-0.5,size=4)
ggsave("../Results/Graphs/National_vs_Grade_Bar.jpg",width=10,height=10,p3)
p3
tbl1=table(df2$Department,df2$Grade)
chi1<- chisq.test(tbl1)
c1 = chi1$expected
tidy(chi1)
obs_exp1 = data.frame(cbind(tbl1, c1))
names(obs_exp1)=c("A","B", "Expected A", "Expected B" )
obs_exp1
tbl2=table(df2$Programming,df3$Grade)
chi2<- chisq.test(tbl2)
c2 = chi2$expected
tidy(chi2)
obs_exp2 = data.frame(cbind(tbl2, c2))
names(obs_exp2)=c("A","B", "Expected A", "Expected B" )
obs_exp2
tbl3=table(df3$International,df3$Grade)
chi3<- chisq.test(tbl3)
c3 = chi3$expected
tidy(chi3)
obs_exp3 = data.frame(cbind(tbl3, c3))
names(obs_exp3)=c("A","B", "Expected A", "Expected B" )
obs_exp3
tbl4=table(df3$International,df3$Programming)
chi4<- chisq.test(tbl4)
c4 = chi4$expected
tidy(chi4)
obs_exp4 = cbind(tbl4, c4)
names(obs_exp4)=c("No","Yes", "Expected No", "Expected Yes" )
obs_exp4
tbl5=table(df3$Department,df3$International)
chi5<- chisq.test(tbl5)
c5 = chi5$expected
tidy(chi5)
obs_exp5 = cbind(tbl5, c5)
names(obs_exp5)=c("No","Yes", "Expected No", "Expected Yes" )
obs_exp5
tbl6=table(df2$Department,df2$Programming)
chi6<- chisq.test(tbl6)
c6 = chi6$expected
tidy(chi6)
obs_exp6 = cbind(tbl6, c6)
names(obs_exp6)=c("No","Yes", "Expected No", "Expected Yes" )
obs_exp6
tbl7=table(df4$Department,df4$Knowledge)
chi7<- chisq.test(tbl7)
c7 = chi7$expected
tidy(chi7)
obs_exp7 = cbind(tbl7, c7)
names(obs_exp7)=c("No","Yes", "Expected No", "Expected Yes" )
obs_exp7
tbl8=table(df4$Programming,df4$Knowledge)
chi8<- chisq.test(tbl8)
c8 = chi8$expected
tidy(chi8)
obs_exp4 = data.frame(cbind(tbl4, c4))
names(obs_exp4)=c("No","Yes", "Expected No", "Expected Yes" )
obs_exp4
tbl2=table(df2$Programming,df2$Grade)
chi2<- chisq.test(tbl2)
c2 = chi2$expected
tidy(chi2)
pt(1.733, df=162, lower.tail = F)
pt(1.733, df=162, lower.tail = F)*2
setwd("C:/Users/ddinh4/Downloads")
df1 = read.csv("Statistics_2016.csv")
df1[df1$Instructor=="INS1"]
df1[df1$Instructor=="INS1",]
length(df1[df1$Instructor=="INS1",])
nrow(df1[df1$Instructor=="INS1",])
nrow(df1[df1$Instructor=="INS2",])
nrow(df1[df1$Instructor=="INS3",])
nrow(df1[df1$Instructor==c("INS1","INS2","INS3"),])
nrow(df1[df1$Instructor==c("INS1","INS2","INS3"),])
levels(df1$Instructor)
df1$Instructor <- as.factor(df1$Instructor)
levels(df1$Instructor)
length(levels(df1$Instructor))
nrow(levels(df1$Instructor))
table(df1$Instructor)
curve(dgamma(x, shape = a, rate = a/70), col = "grey", lwd = 3, xlab = "X", ylab = "Density",
ylim = c(0, .08), xlim = c(0, 300))
curve(dnorm(x, mean = 70, sd = 31.3), add = TRUE, col = "green", lwd = 5)
legend(200,.08,c("Gamma","Normal"),lty=1,lwd=4,col=c("grey","green"))
dgamma(50, shape = a, rate = a/70)
a = 5
x <- seq(0, 50, by = 0.1)
curve(dgamma(x, shape = a, rate = a/70), col = "grey", lwd = 3, xlab = "X", ylab = "Density",
ylim = c(0, .08), xlim = c(0, 300))
curve(dnorm(x, mean = 70, sd = 31.3), add = TRUE, col = "green", lwd = 5)
legend(200,.08,c("Gamma","Normal"),lty=1,lwd=4,col=c("grey","green"))
dgamma(50, shape = a, rate = a/70)
dnorm(50, mean = 70, sd = 31.3)
a = 5
x <- seq(0, 50, by = 0.1)
curve(dgamma(x, shape = a, rate = a/70), col = "grey", lwd = 3, xlab = "X", ylab = "Density",
ylim = c(0, .08), xlim = c(0, 300))
curve(dnorm(x, mean = 70, sd = 31.3), add = TRUE, col = "green", lwd = 5)
legend(200,.08,c("Gamma","Normal"),lty=1,lwd=3,col=c("grey","green"))
dgamma(50, shape = a, rate = a/70)
dnorm(50, mean = 70, sd = 31.3)
a = 5
x <- seq(0, 50, by = 0.1)
curve(dgamma(x, shape = a, rate = a/70), col = "grey", lwd = 3, xlab = "X", ylab = "Density",
ylim = c(0, .08), xlim = c(0, 300))
curve(dnorm(x, mean = 70, sd = 31.3), add = TRUE, col = "green", lwd = 3)
legend(200,.08,c("Gamma","Normal"),lty=1,lwd=3,col=c("grey","green"))
dgamma(50, shape = a, rate = a/70)
dnorm(50, mean = 70, sd = 31.3)
curve(dtnorm(x, mean = 70, sd = 31.3,0,500), add = TRUE, col = "green", lwd = 3)
install.packages("msm")
curve(dgamma(x, shape = a, rate = a/70), col = "grey", lwd = 3, xlab = "X", ylab = "Density",
ylim = c(0, .08), xlim = c(0, 300))
curve(dtnorm(x, mean = 70, sd = 31.3,0,500), add = TRUE, col = "green", lwd = 3)
legend(200,.08,c("Gamma","Normal"),lty=1,lwd=3,col=c("grey","green"))
library(msm)
curve(dgamma(x, shape = a, rate = a/70), col = "grey", lwd = 3, xlab = "X", ylab = "Density",
ylim = c(0, .08), xlim = c(0, 300))
curve(dtnorm(x, mean = 70, sd = 31.3,0,500), add = TRUE, col = "green", lwd = 3)
legend(200,.08,c("Gamma","Normal"),lty=1,lwd=3,col=c("grey","green"))
curve(dgamma(x, shape = a, rate = a/70), col = "grey", lwd = 3, xlab = "X", ylab = "Density",
ylim = c(0, .08), xlim = c(0, 300))
curve(dnorm(x, mean = 70, sd = 31.3,0,500), add = TRUE, col = "green", lwd = 3)
legend(200,.08,c("Gamma","Normal"),lty=1,lwd=3,col=c("grey","green"))
curve(dgamma(x, shape = a, rate = a/70), col = "grey", lwd = 3, xlab = "X", ylab = "Density",
ylim = c(0, .08), xlim = c(0, 300))
curve(dtnorm(x, mean = 70, sd = 31.3,0,500), add = TRUE, col = "green", lwd = 3)
legend(200,.08,c("Gamma","Normal"),lty=1,lwd=3,col=c("grey","green"))
curve(dgamma(x, shape = a, rate = a/70), col = "grey", lwd = 3, xlab = "X", ylab = "Density",
ylim = c(0, .08), xlim = c(0, 300))
curve(dnorm(x, mean = 70, sd = 31.3), add = TRUE, col = "green", lwd = 3)
legend(200,.08,c("Gamma","Normal"),lty=1,lwd=3,col=c("grey","green"))
setwd("~/EXST 7151/Final Project/Data")
df1 = read.csv("data_date.csv")
unique_data <- data %>% distinct(Country, .keep_all = TRUE)
library(dplyr)
df1 = read.csv("data_date.csv")
unique_data <- data %>% distinct(Country, .keep_all = TRUE)
library(ggplot2)
library(dplyr)
df1 = read.csv("data_date.csv")
unique_data <- data %>% distinct(Country, .keep_all = TRUE)
View(df1)
unique_data <- data %>% distinct(Country, .keep_all = TRUE)
unique_data <- df1 %>% distinct(Country, .keep_all = TRUE)
aqi_2 <- unique_data[,c("Status","AQI_Value")]
aqi <- aqi_2[,2]
aqi <-  aqi[aqi <= 500]
aqi_df <- data.frame(aqi)
install.packages("MCMCpack")
library(MCMCpack)
mu = mean(aqi)
sigma2 = var(aqi)
likelihood <- function(aqi, mu, sigma2)
prod(dnorm(aqi, mu, sqrt(sigma2))
a = 5
x <- seq(0, 50, by = 0.1)
mu0 <- dnorm(x, mean = 70, sd = sqrt((70^2)/5))
sigma02 <- dinvgamma(x, 0.1, 0.1)
likelihood_M1 <- integrate(likelihood*mu0*sigma02, 0, Inf)
#Normal model for data with unknown mu and sigma^2
mu = mean(aqi)
sigma2 = var(aqi)
likelihood <- function(aqi, mu, sigma2)
prod(dnorm(aqi, mu, sqrt(sigma2))
a = 5
likelihood <- function(aqi, mu, sigma2)
prod(dnorm(aqi, mu, sqrt(sigma2))
a = 5
a = 5
x <- seq(0, 50, by = 0.1)
mu0 <- dnorm(x, mean = 70, sd = sqrt((70^2)/5))
sigma02 <- dinvgamma(x, 0.1, 0.1)
library(MCMCpack)
install.packages("MatrixModels")
library(MCMCpack)
library(MCMCpack)
install.packages("MatrixModels")
library(MCMCpack)
sigma02 <- dinvgamma(x, 0.1, 0.1)
